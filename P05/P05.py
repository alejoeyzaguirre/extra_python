# -*- coding: utf-8 -*-
"""P05.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AdU-eYmDNfVaP66iT-ajvmXHJ48RQBd5

# Actividad Práctica 05: Herramientas Avanzadas de Python

Aplicando contenidos de `Webscrapping` y `Regex`. 

1. Las páginas a *scrapear* son las siguientes: www.yr.no y www.weather.com.
2. Las ciudades son Santiago, Boston y Oslo.
3. La variable a *scrapear* es el viento (velocidad).
4. Hacer la función.

Para desarrollar esto usaremos entonces 6 links distintos. Uno para cada ciudad y página. De esta forma usando expresiones regulares y web-scrapping podremos extraer la información de viento en su unidad de velocidad, para ambas páginas, para distintos días.

Antes que nada instalemos las librerías a utilizar.

#### Instalación de Librerías
"""

!pip3 install pyrematch



"""## Paso I: Obtener variable metereológica seleccionada.

Partamos con lo primero que es más que nada obtener la variable metereológica obtenida por mi. Para ello partiremos con la página web de weather.com. El link que se utilizará es el específico del pronóstico para los días que se vienen para Oslo, Noruega. Los pasos llevados a cabo para extraer la info de Oslo, debieran ser los mismos para las otras 2 ciudades, ya que es probable que la plataforma, cumpla con el mismo formato para las otras ciudades.

Los pasos a seguir para yr.no serán distintos.
"""

import urllib.request as net
import ssl

class WebDownloader:
    
    def __init__(self, link):
        self.user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'
        self.url =  link
        
        
    def getHtmlAsString(self):
        headers = {'User-Agent':self.user_agent}
        request= net.Request(self.url,None,headers)
        gcontext = ssl.SSLContext()
        response = net.urlopen(request,context=gcontext)
        return response.read().decode('utf-8')
    
wd = WebDownloader('https://weather.com/es-CL/tiempo/10dias/l/91bd58d378e68f0f8e4037428d76095f05cb5d31e1d0e6b3ea8bea36540fe81a#detailIndex5')
sourceCode = wd.getHtmlAsString()
print(sourceCode)

"""Habiendo obtenido nuestra sopa, procedemos a extraer la información de viento, para ello debemos primero inspeccionar el elemento de viento en km/h de la página web `weather.com`.

Inspeccionando el elemento de de viento en km/h, notamos que este se encuentra dentro de un apartados del tipo `span`, debemos entonces extraer a partir de ese criterio la info dentro de algún span.

Luego más adelante extraeremos a partir de expresiones regulares la fecha y el viento en km/h de cada uno de los días en particular.
"""

import bs4
info = []
soup = bs4.BeautifulSoup(sourceCode)
for node in soup.findAll('span'):
    info.append(str(u''.join(node.findAll(text=True)).encode('utf-8')))

print(info)
print()

"""Notamos que de partida cada dato relevante se encuentra siempre después de una secuencia de caracteres del tipo `"b`. Tanto la fecha, como la humedad se encuentran después de esta secuencia. Además cada dato es cerrado por un signo de comillas dobles que también nos gustaría despejar.(").

Tratemos ahora de despejar este caracter, filtrando las comillas dobles y esa b.
"""

info = []
soup = bs4.BeautifulSoup(sourceCode)
for node in soup.findAll('span'):
    info.append(str(u''.join(node.findAll(text=True)).encode('utf-8'))[2:-1])

print(info)

"""El patrón para extraer nuestra información relevante, de viento en km/h; entonces es el siguiente:

`^[A-Z]+[A-Z]?+[A-Z]?\s\s[0-9]+[0-9]+[0-9]?\skm.h$`

NOTA: Gracias Pablo, por la sugerencia de usar regex101.com, me fue muy útil!.

Primero debemos filtrar las observaciones de nuestra lista que son de viento, y luego purificamos la observación en lo que nos interesa obtener.

"""

import pyrematch as re

seq = info
pattern = "^[A-Z]{1,3}\s\s[0-9]+[0-9]+[0-9]?\skm.h$"
regex = re.compile(pattern)

vientos = []
for s in seq:
    if regex.find(s):
      vientos.append(s)

print(vientos)

"""Ahora extraigamos la fecha de cada una de estas obseraciones. Notamos que esta se encuentra en info, o seq con el día en 3 letras **minúsculas** con un punto que las cierra y luego un espacio y finalmente dos caracteres alfanuméricos. Hagamos el mismo proceso."""

pattern2 = "^[a-z]{1,3}.?.?[a-zA-Z0-9]{2,3}?.?.?[a-z0-9]{1,4}?.\s[0-9]{2,3}$"
regex = re.compile(pattern2)

fechas = []
for s in seq:
    if regex.find(s):
      fechas.append(s)

print(fechas)

"""Estudiamos el largo de ambas listas:"""

len(fechas)

len(vientos)

"""Viendo la información notamos que los primeros 3 vientos corresponden al día de hoy. Estos entonces no deben ser considerados. Además aprovechamos de deshacernos de la primera fecha, que corresponde el día de hoy."""

vientos = vientos[3:]
fechas = fechas[1:]

print(vientos)

"""Además podemos notar que por cada día hay 3 informaciones de vientos distintas. A modo de simplificación nos quedamos con la de la mitad del día suponiendo que la otra página web nos entregará solo una información de viento al día.
Tenemos entonces tres vientos al día y tenemos en total 28 fechas dobles, como tenemos elementos repetidos los eliminamos.
"""

fechas2 = []
for i in range(len(fechas)):
  if i % 2 == 0:
    fechas2.append(fechas[i])

print(fechas2)

fechas = fechas2

len(fechas)

"""Ahora trabajemos con mi página favorita del tiempo (a mi gusto la mejor para el sur de Chile) `yr.no`:"""

wd2 = WebDownloader('https://www.yr.no/en/forecast/daily-table/1-72837/Norway/Oslo/Oslo/Oslo')
sourceCode = wd2.getHtmlAsString()
print(sourceCode)

info = []
soup = bs4.BeautifulSoup(sourceCode)
for node in soup.findAll('li'):
    info.append(str(u''.join(node.findAll(text=True, recursive = True)).encode('utf-8')))

print(info)
print()

"""Habiendo obtenido, esta lista `info` que contiene la información de los vientos u otros datos relevantes, procedemos a extraer de esta lista nuestros datos relevantes."""

seq = info
pattern = "Wind"
regex = re.compile(pattern)

vientos = []
for s in seq:
    if regex.find(s):
      vientos.append(s)

vientos

"""Con este último paso logramos tener los elementos de la lista relevantes para extraer la información. En cada uno de estos tenemos la fecha y el viento en m/s (millas por segundo).
Procedamos a extraer cada uno de estos por separado.
"""

seq = vientos
pattern = "(Wind :)!text{[^,]+}(Open)"

regex = re.compile(pattern)

vientos = []
for s in seq:
  for match in regex.finditer(s):
    vientos.append(match.group('text'))

vientos

"""Estos sería los vientos para los 7 días siguientes (el primer dato es el de hoy, lo debemos eliminar)."""

vientos = vientos[1:]

"""Ahora extraemos las fechas, con el mismo método. Sabemos que el mes será diciembre o el siguiente mes. Por lo que extraemos desde Dec y hasta Night."""

pattern = "(Dec. )!text{[^,]+}(Night)"

regex = re.compile(pattern)

fechas = []
for s in seq:
  for match in regex.finditer(s):
    fechas.append(match.group('text'))

fechas

"""Extraemos la fecha del día de hoy (4 de diciembre en Noruega es hoy)."""

fechas = fechas[1:]